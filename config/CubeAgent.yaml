behaviors:

  CubeAgent:

    trainer_type: ppo

    hyperparameters:

      batch_size: 10

      buffer_size: 100

      learning_rate: 0.0003

      beta: 0.005

      epsilon: 0.2

      lambd: 0.99

      num_epoch: 3

      learning_rate_schedule: linear
      
      beta_schedule: constant
      
      epsilon_schedule: linear

    network_settings:

      normalize: false

      hidden_units: 128

      num_layers: 2

      vis_encode_type: simple

    reward_signals:

      extrinsic:

        gamma: 0.90

        strength: 1.0

    keep_checkpoints: 5

    max_steps: 100000

    time_horizon: 64

    summary_freq: 2000

    threaded: true
    
  CubeAgentRay:

    trainer_type: ppo

    hyperparameters:

      batch_size: 10

      buffer_size: 100

      learning_rate: 0.0003

      beta: 0.005

      epsilon: 0.2

      lambd: 0.99

      num_epoch: 3

      learning_rate_schedule: linear
      
      beta_schedule: constant
      
      epsilon_schedule: linear

    network_settings:

      normalize: false

      hidden_units: 128

      num_layers: 2

      vis_encode_type: simple

    reward_signals:

      extrinsic:

        gamma: 0.90

        strength: 1.0

    keep_checkpoints: 5

    max_steps: 100000

    time_horizon: 64

    summary_freq: 2000

    threaded: true
    
  CubeAgentCam:

    trainer_type: ppo

    hyperparameters:

      batch_size: 10

      buffer_size: 100

      learning_rate: 0.0003

      beta: 0.005

      epsilon: 0.2

      lambd: 0.99

      num_epoch: 3

      learning_rate_schedule: linear
      
      beta_schedule: constant
      
      epsilon_schedule: linear

    network_settings:

      normalize: false

      hidden_units: 128

      num_layers: 2

      vis_encode_type: simple

    reward_signals:

      extrinsic:

        gamma: 0.90

        strength: 1.0

    keep_checkpoints: 5

    max_steps: 100000

    time_horizon: 64

    summary_freq: 2000

    threaded: true
    
  CubeAgentZoneRay:

    trainer_type: ppo

    hyperparameters:

      batch_size: 10

      buffer_size: 100

      learning_rate: 0.0003

      beta: 0.005

      epsilon: 0.2

      lambd: 0.99

      num_epoch: 3

      learning_rate_schedule: linear
      
      beta_schedule: constant
      
      epsilon_schedule: linear

    network_settings:

      normalize: false

      hidden_units: 128

      num_layers: 2

      vis_encode_type: simple

    reward_signals:

      extrinsic:

        gamma: 0.90

        strength: 1.0

    keep_checkpoints: 5

    max_steps: 400000

    time_horizon: 64

    summary_freq: 2000

    threaded: true
    
  CubeAgentZoneRay-2:

    trainer_type: ppo

    hyperparameters:

      batch_size: 10

      buffer_size: 100

      learning_rate: 0.0003

      beta: 0.005

      epsilon: 0.2

      lambd: 0.99

      num_epoch: 3

      learning_rate_schedule: linear
      
      beta_schedule: constant
      
      epsilon_schedule: linear

    network_settings:

      normalize: false

      hidden_units: 128

      num_layers: 2

      vis_encode_type: simple

    reward_signals:

      extrinsic:

        gamma: 0.90

        strength: 1.0
        
      curiosity:
        
        strength: 0.1
        
        gamma: 0.99
        
        encoding_size: 256
        
        learning_rate: 1e-3

    keep_checkpoints: 5

    max_steps: 100000

    time_horizon: 64

    summary_freq: 2000

    threaded: true
    
  CubeAgentZoneRay-3:

    trainer_type: ppo

    hyperparameters:

      batch_size: 10

      buffer_size: 100

      learning_rate: 0.0003

      beta: 0.005

      epsilon: 0.2

      lambd: 0.99

      num_epoch: 3

      learning_rate_schedule: linear
      
      beta_schedule: constant
      
      epsilon_schedule: linear

    network_settings:

      normalize: false

      hidden_units: 128

      num_layers: 2

      vis_encode_type: simple

    reward_signals:

      extrinsic:

        gamma: 0.90

        strength: 1.0
        
      curiosity:
        
        strength: 0.075
        
        gamma: 0.99
        
        encoding_size: 256
        
        learning_rate: 1e-3

    keep_checkpoints: 5

    max_steps: 100000

    time_horizon: 64

    summary_freq: 2000

    threaded: true
    
  CubeAgentZoneRay-4:

    trainer_type: ppo

    hyperparameters:

      batch_size: 10

      buffer_size: 100

      learning_rate: 0.0003

      beta: 0.005

      epsilon: 0.2

      lambd: 0.99

      num_epoch: 3

      learning_rate_schedule: linear
      
      beta_schedule: constant
      
      epsilon_schedule: linear

    network_settings:

      normalize: false

      hidden_units: 128

      num_layers: 2

      vis_encode_type: simple

    reward_signals:

      extrinsic:

        gamma: 0.90

        strength: 1.0
        
      curiosity:
        
        strength: 0.05
        
        gamma: 0.99
        
        encoding_size: 256
        
        learning_rate: 1e-3

    keep_checkpoints: 5

    max_steps: 100000

    time_horizon: 64

    summary_freq: 2000

    threaded: true
    
  CubeAgentZoneRay-5:

    trainer_type: ppo

    hyperparameters:

      batch_size: 10

      buffer_size: 100

      learning_rate: 0.0003

      beta: 0.005

      epsilon: 0.2

      lambd: 0.99

      num_epoch: 3

      learning_rate_schedule: linear
      
      beta_schedule: constant
      
      epsilon_schedule: linear

    network_settings:

      normalize: false

      hidden_units: 128

      num_layers: 2

      vis_encode_type: simple

    reward_signals:

      extrinsic:

        gamma: 0.90

        strength: 1.0
        
      curiosity:
        
        strength: 0.025
        
        gamma: 0.99
        
        encoding_size: 256
        
        learning_rate: 1e-3

    keep_checkpoints: 5

    max_steps: 100000

    time_horizon: 64

    summary_freq: 2000

    threaded: true
    
  CubeAgentZoneRay-6:


    trainer_type: ppo

    hyperparameters:

      batch_size: 10

      buffer_size: 100

      learning_rate: 0.0003

      beta: 0.005

      epsilon: 0.2

      lambd: 0.99

      num_epoch: 3

      learning_rate_schedule: linear
      
      beta_schedule: constant
      
      epsilon_schedule: linear

    network_settings:

      normalize: false

      hidden_units: 128

      num_layers: 2

      vis_encode_type: simple

    reward_signals:

      extrinsic:

        gamma: 0.90

        strength: 1.0
        
      curiosity:
        
        strength: 1.0
        
        gamma: 0.99
        
        encoding_size: 256
        
        learning_rate: 1e-3

    keep_checkpoints: 5

    max_steps: 100000

    time_horizon: 64

    summary_freq: 2000

    threaded: true